{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 기초 3강(2018.08.25)\n",
    "***    \n",
    "\n",
    "* __강의 목표__: 기계 학습에 대한 기본 용어 학습  \n",
    "\n",
    "* __이론__: 경사하강법 위주 (Learning problem, computational graph )\n",
    "\n",
    "* __실습__:  R 기초    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#기본 옵션\n",
    "options(repr.plot.width=4, repr.plot.height=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# 0.요약  \n",
    "1. filter: 결과값을 원하는 방식으로 나타내는 것   \n",
    "\n",
    "2. 통계 학파: 빈도주의/ 베이즈 주의\n",
    "http://gentlej90.tistory.com/61\n",
    "\n",
    "3. 베이즈 정리: 고등학교 때 배운 조건부 서식\n",
    "4. 베이즈 정리의 의의\n",
    "> prior(이미 알고 있는 비율)  \n",
    "  likelihood (사건이 발생할 확률: 가능도)   \n",
    "  posterior (발생한 결과)  \n",
    "\n",
    "> posterior: 이미 알고 있는 결과를 의심 -> 새로운 데이터를 찾음  \n",
    "likelihood: 특정 전제하에서 사건이 발생할 가능성을 고려 -> 새로운 모델 (뉴턴), 딥러닝, model selection  \n",
    "http://rstudio-pubs-static.s3.amazonaws.com/204928_c2d6c62565b74a4987e935f756badfba.html\n",
    "\n",
    "5. 확률을 이용해 classification을 푸는 2가지 방법    \n",
    "> MAP(Maximum A Posterior) : 결과 기준이라 다 더하면 100% (계산 어려움)\n",
    "  MLE(Maximum Likelihood Estimation) : 더 큰 확률을 선택 (많이 사용)  \n",
    "    - 장점: posterior보다 계산하기 쉬움\n",
    "    - 단점: training에는 맞지만, 실제 data와 차이 있을 수 있음(일반화의 오류)\n",
    " \n",
    "6. classification의 loss \n",
    "> 각 모델의 loss 값을 곱한다. \n",
    "\n",
    "7. 로그 법칙\n",
    "> 로그 씌우면 지수가 로그 앞으로 가서 계산이 쉬워지고, 보기도 편해진다.\n",
    "\n",
    "8. one-hot-encoding\n",
    "> ouput 여러개여도 행열로 표현 가능\n",
    "https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f\n",
    " \n",
    "9. 시그모이드 필터\n",
    ">범주형 데이터를 0과 1사이의 연속된 숫자로 바꿔주는 함수    \n",
    "logistic linear model 이라고도 함\n",
    "10. softmax 함수: 시그모이드 필터와 동일(조건: 양수, 합=1), 비선형은 안됨  \n",
    "\n",
    "11. MLP(Multilayer Perception)\n",
    "> 파라미터 갯수 계산하는 법 중요, eg) 신경망\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시그모이드 필터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필터\n",
    "Sigmoid <- function(x){\n",
    "  s <- 1 / (1 +exp(-x))\n",
    "  return(s)\n",
    "}\n",
    "\n",
    "Machine_Sigmoid <- function(x, w, b){\n",
    "  result <- Sigmoid(x*w+b)  # 1차 함수 돌렸을 떄의 값을 리턴해줌\n",
    "  return(result)\n",
    "  \n",
    "}\n",
    "\n",
    "Cost_Sigmoid <- function(x, w, b, y) {\n",
    "  y_hat <- Machine_Sigmoid(x,w,b) #예측값\n",
    "  loss <- -( y * log(y_hat) + (1 - y) * log(1-y_hat) ) \n",
    "  cost <- mean(loss) # 제곱한 것의 평균\n",
    "  return(cost) \n",
    "}\n",
    "\n",
    "Gradient_Sigmoid <- function(x, w, b, y){\n",
    "  dw <- ( Cost_Sigmoid(x, w + 0.0001, b, y) - Cost_Sigmoid(x, w, b, y) )/0.0001 \n",
    "  db <- ( Cost_Sigmoid(x, w, b + 0.0001, y) - Cost_Sigmoid(x, w, b, y) )/0.0001\n",
    "  grad <-list(dw=dw, db=db)\n",
    "  return(grad)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>10</li>\n",
       "\t<li>2</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 10\n",
       "\\item 2\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 10\n",
       "2. 2\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 10  2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "     money            happiness  \n",
       " Min.   :-1.70336   Min.   :0.0  \n",
       " 1st Qu.:-0.40986   1st Qu.:0.0  \n",
       " Median : 0.11657   Median :0.5  \n",
       " Mean   : 0.05704   Mean   :0.5  \n",
       " 3rd Qu.: 0.51771   3rd Qu.:1.0  \n",
       " Max.   : 1.97308   Max.   :1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t10 obs. of  2 variables:\n",
      " $ money    : num  -1.70336 -1.25799 -0.54499 -0.00445 0.11019 ...\n",
      " $ happiness: int  0 0 0 1 1 0 0 1 1 1\n"
     ]
    }
   ],
   "source": [
    "test_df <- read.csv(\"data3_1.csv\", header = TRUE) \n",
    "dim(test_df)\n",
    "summary(test_df)\n",
    "str(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAFoCAMAAAC46dgSAAAAOVBMVEUAAAAAAP9NTU1oaGh8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\nwaFgcCgYHAoGh4LB+Q+Mu/qJMfDwcgAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lm 함수의 선형 회귀\n",
    "plot(test_df$money, test_df$happiness, pch=19, cex=1, col=\"grey\")\n",
    "abline(lm(happiness~money, data=test_df), lwd=5, col=\"red\")\n",
    "\n",
    "#초기값\n",
    "w<-0\n",
    "b<-0\n",
    "\n",
    "#1000번 학습\n",
    "for(i in 1:1000){\n",
    "  grad <- Gradient_Sigmoid(x=test_df$money, y=test_df$happiness, w=w, b=b)\n",
    "  w<- w - 0.01*grad$dw\n",
    "  b<- b - 0.01*grad$db\n",
    "}\n",
    "\n",
    "\n",
    "#학습 후의 곡선\n",
    "temp <- seq(-3, 3, length=1000)\n",
    "points(temp, Machine_Sigmoid(temp, w, b), lwd=5, type='l', col='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4강에서 배울 내용__  \n",
    "  \n",
    ">1강: 머신러닝 기초, 2강: regression(수치), 3강: classification(범주형)을 배웠으면    \n",
    "어디까지 학습해야되는지를 보기 위해 `overfitting`을 배움  \n",
    "\n",
    "> - 예측이 맞을 범위를 구하는 VC 이론    \n",
    "> - 모델의 정확도를 평가하는 model assessment, cross validation  \n",
    "> - 평가를 하는 여러 기준인 validation set(k-fold, LOO)  \n",
    "> - 함수의 복잡도(크기)  \n",
    "> - shrinkage method: ridge/ lasso  \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
