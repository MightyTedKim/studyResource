{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 러닝 기초 4강(2018.09.01)\n",
    "***    \n",
    "\n",
    "* __강의 목표__: Overfitting에 대한 이해\n",
    "\n",
    "* __이론__: VC 이론, cross-validation, model selection, 복잡도, Shrinkage\n",
    "\n",
    "* __실습__: \n",
    "> - LASSO: sparsity, 파라미터 크기  \n",
    " - Ridge: 파라미터 크기  \n",
    " - Elastic net(glmnetUtils): 함수의 복잡도 설명  \n",
    " - Hyperparameter 튜닝 방법, lambda  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4강 Overfitting 관련 질문  \n",
    "\n",
    "__Q1. feature selection과 lasso/ridge와의 관계__\n",
    "> \n",
    "> 학습 공식: traingingLoss(h) + A * R(h)    \n",
    "  공식 해석: R(h) < B, 특정 조건 만족하는 상황에서 training Loss를 최소화하자  \n",
    "\n",
    "> Feature Selection : L0 Norm = 벡터 워소 중 0이 아닌 것의 개수, 적은 수의 파라미터만 0이 아닌 값을 갖도록  \n",
    "> Lasso : L1 Norm, 전체적인 파라미터 벡트 크기 작아지도록  \n",
    "> Ridge : L2 Norm, \n",
    "\n",
    "--- \n",
    "\n",
    "__Q1-2 L0 Norm은 소수의 파라미터만 0이 아닌 값을 가지게 된다고 답 주셨는데, 그건 Lasso의 sparsity 특성 아닌가요?  \n",
    "L0/L1을 함꼐 이해하려니 혼란스러워요__    \n",
    "\n",
    ">    \n",
    "\n",
    "---\n",
    "\n",
    "__Q2. wine 데이터에서 model_all이랑 model_type의 파라미터 값이 왜 같은지 정확히 이해가 안가요\n",
    "그래서 tree에서 mtry를 고르는게 좀 헷갈린 거 같기도 하고__\n",
    "\n",
    "> 제가 질문 자체를 잘못한 것 같아요. 모든 변수를 고려했을 때가 model_all/ 특정 변수만 고려한게 model_type이고   \n",
    "고려하는 변수가 다르니 결과도 다르다는 것 같아요 \n",
    "  \n",
    "<img src=\"./wine_capture.PNG\" width=\"400\">\n",
    "  \n",
    "> 쌤 답변: type 변수의 부호가 다른데 이건 해석할 문제가 있을 가능성이 크다는 것.   \n",
    "modell_all에서는 화이트와인의 질이 낮다는 결론,   \n",
    "model_type은 화이트와인의 질이 좋다는 결론이 나왔으니까  \n",
    "\n",
    "__Q3. glmnetUnits(generalized linear model)는 lasso/ridge를 적당히 섞은 건가요?__\n",
    "> Yes, L1/L2 norm을 모두 사용하는 형태의 regularization임  \n",
    "> alpha(가중치) 가 1이면 lasso에 가깝고, 0이면 ridge에 가까움   \n",
    "> lambda(제약화의 세기) 도 하이퍼 파라미터임  \n",
    "\n",
    "__Q4. validation set approach 안에 kfold와 loo cv 가 있는건가요?   \n",
    "    아니면 validation set approach는 validation 한번만 한거고 여러번 한것이 cross validation)인건가요? __  \n",
    "    \n",
    ">\n",
    "   \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A1. 학습이라는게 사실 이런거였죠? 'Training_Loss(h) + (어떤 숫자 A) * R(h)를 최소화하라' 근데 사실 저런 문제를 'R(h) < (어떤 숫자 B)를 만족하면서, Training_Loss(h)를 최소화하라' 이렇게도 쓸 수 있어요. (어떤 숫자 A에 대응되는 어떤 숫자 B가 항상 존재하구요.) 그래서 저 두 최적화 문제는 사실 같은 문제의 서로 다른 두 가지 표현이기 때문에 서로를 Lagrange Dual 관계라고 얘기해요. 수업에서는 전자의 형태로 설명했지만 사실 정성적으로 이해하기에는 후자의 형태가 좀 더 편하죠. R(h)를 L1 norm으로 설정하면 LASSO, L2 norm으로 설정하면 Ridge였죠? L0 norm인 경우가 Feature Selection이라는건데, 왜 그러냐면 L0 norm가 단순히 벡터의 원소 중 0이 아닌 것의 개수이기 때문이에요. 가령 (1,2,3,1,0,0,-1)같은 벡터의 L0 norm은 5라는거죠. 우리가 다루는게 parametric model이니 R(h)를 L0 norm으로 설정하면 파라미터 중 0이 아닌 것의 개수이고, 결국에 학습은 '(파라미터 중 0이 아닌 것의 개수) < (어떤 숫자 B)를 만족하면서, Training_Loss(h)를 최소화하라'가 되겠죠. 가령 (어떤 숫자 B)를 3이라고 한다면, 파라미터 중 0이 아닐 수 있는건 많아봐야 2개겠죠. 선형 회귀의 경우에는 변수 2개만을 선택하는 상황이 될거구요. L0 norm을 사용하는게 적은 수의 파라미터만 0이 아닌 값을 갖도록 강제하는거라면, L1 norm을 사용하는건 전체적인 파라미터 벡터의 크기가 작아지기를 바라는거에요. 그런데 사실상 람다(어떤 숫자 A)를 크게 하면 할수록 학습된 파라미터들은 소수만 0이 아닌 값을 가지게 되고, 결국엔 Feature Selection이 되는것과 비슷한 효과를 준다는겁니다!\n",
    "\n",
    "A2. 파라미터의 값이 같다는게 정확히 무슨 말인지 잘 모르겠네요. 파라미터의 값이 다르지 않나요? 그것보다 type 변수에 해당하는 파라미터들의 부호가 달라지는데, 그건 해석할 때 문제가 있을 수 있다는거죠. 왜냐면 model_all에서는 화이트와인의 질이 낮다는 결론을 얻고, model_type에서는 반대의 결론이 나오니까요. 이런건 다중공선성 때문에 발생하는 문제인데 다중공선성을 보이는 변수를 빼 주거나 (VIF라는 통계량을 확인합니다.) Ridge regularization을 사용하면 어느 정도 해소가 되기도 합니다. (질문을 제대로 이해했는지 모르겠네요.)\n",
    "\n",
    "A3. R1(w)을 L1 norm, R2(w)를 L2 norm이라고 하면 elastic net은 'Training_Loss(h) + lambda * (alpha * R1(w) + (1-alpha) * R2(w))를 최소화하라'가 됩니다. alpha가 1이면 LASSO, 0이면 ridge인데, 0과 1 사이의 값을 사용하면 L1, L2 norm을 모두 사용하는 형태의 Regularizaiton이 되겠죠. 따라서 L1와 L2 간 가중치를 조절해주는 alpha, 제약화의 세기를 조절해주는 lambda가 하이퍼파라미터가 됩니다.\n",
    "\n",
    "A4. 제가 수업에서 설명한 알고리즘은 Decision Tree 중 CART입니다. CART는 회귀, 분류 문제를 푸는데 모두 사용할 수 있는데, 저는 회귀 문제를 푸는 경우에 대해 설명했습니다. 분류 문제는 아주 조금 더 까다로워질 수 있는데, 연습문제 삼아서 한번 해 보시는걸 추천드려요. 아마 교재들에서는 \"불순도를 최소화하도록 split한다\"라고 써 있을텐데, 이렇게 생각하시는 것 보다 Logistic Regression에서 했던것처럼 \"logloss를 최소화한다\"라고 생각해보시고 이게 곧 \"불순도를 최소화한다\"와 같은 말이라는걸 유도해보시면 좋을 것 같네요.\n",
    "\n",
    "A5. 앙상블은 모델 여러개를 합치는 기법들을 모두 그렇게 부릅니다. bagging과 boosting은 앙상블 기법의 일종이구요. (이외에 stacking이라는 기법도 존재합니다.) 랜덤포레스트는 decision tree로 구성된 bagging의 특별한 경우라고 보시면 될 것 같아요.\n",
    "\n",
    "A6. bagging과 boosting은 다 \"나무1 + 나무2 + ... + 나무B\" 이렇게 생겼습니다. 그런데 나무를 어떻게 만들어 나가느냐의 차이죠. bagging은 '샘플링 -> 나무1', '샘플링 -> 나무2', ... 이렇게 만들어 나간다면 boosting은 '나무1 -> 나무2 -> ...' 이런 식으로 만들어집니다.\n",
    "\n",
    "A7. 랜덤 포레스트나 bagging이 그렇습니다. 나무의 개수를 정해주지 않아도 된다기 보다는, 일정 갯수 이상의 나무를 사용하면 성능이 나빠지지도 좋아지지도 않기 때문에 주의깊게 튜닝해줄 필요가 없다는 의미입니다.\n",
    "\n",
    "A8. mtry는 랜덤 포레스트를 구성하는 개별적인 나무들이 자라 나갈 때, 그냥 자라는게 아니라 랜덤하게 자라도록 제어해주는 역할을 했었죠. (가지를 한번 나눌 때, 모든 input을 고려하지 않고 랜덤추출한 특정한 input만 고려)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#기본 옵션dd\n",
    "options(repr.plot.width=4, repr.plot.height=3)\n",
    "options(scipen=999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "__요약__     \n",
    " \n",
    "1. 과적합의 정의\n",
    "> 모델이 과도하게 학습이 되어, 크게 의미 없는 함수가 나오는 현상\n",
    "  수식:  Ê(ĥ) < E(ĥ), E(ĥ)> Ê(h)\n",
    "  설명: training error(선택된 함수) < training error(전체 함수), \n",
    "      일반화 오류(train set 함수) < 일반화 오류(전체 함수)\n",
    "        \n",
    "2. 머신러닝의 목적  \n",
    "> 예측이 목적, but 통계는 어떤 방향으로 학습(learning)하는지를 알 수 있음  \n",
    " vc 이론을 통해 어디까지 학습해야하는지 알 수 있음\n",
    " \n",
    "3. VC Inequality theory \n",
    "> Ê(ĥ) < E(ĥ) < Ê(ĥ) + bound  \n",
    " 구할 수있는 값, training error<Ê(ĥ)> 로 구할 수 없는 generalization error<E(ĥ)> 추측\n",
    "\n",
    ">  목적: 모든 data가 아닌 training set에 대한 예측 오차를 가장 작게 하는 함수를 찾자\n",
    " ex) \" 나의 키 < 100대 조상의 키 < 나의 키 + 10cm \" 일 것이다.\n",
    "     \n",
    "4. model assesment \n",
    "> 기본 구조 (train > validation > test set)\n",
    "\n",
    "5. validation set을 사용하는 이유\n",
    "> 모델의 성능 평가 /모델의 성능 상승\n",
    "  validation accuracy가 낮으면 overfitting 가능성 높음\n",
    "\n",
    "6. validation 나누는 기준  \n",
    "> validation set approach  \n",
    "> K-fold cv (cross validation)  \n",
    "  LOO CV (leave one out cross-validation)  \n",
    "  \n",
    "7. 함수의 복잡도  \n",
    "> R(h), 함수의 크기, 파라미터의 크기  \n",
    "\n",
    "8. feature selection \n",
    "> Q. feature selection이 정확히 뭔지 모르겠어요. '특징을 선택하고, 원본 데이터의 불필요한 특징 제거'로 이해해서 shrinkage랑 비슷한거 같기도 하고   \n",
    "\n",
    "    > ||w||0: feature selection    \n",
    "\n",
    "    > ||w||1: LASSO regularization (Least Absolute Shrinkage and Selection) \n",
    "       ~ feature selection 기능 있음, sparcity\n",
    "       λ가 빠르게 일부 데이터가 변함\n",
    "\n",
    "    > ||w||2: Ridge regularization (산등성이)\n",
    "       λ가 천천히 모든 데이터가 변함\n",
    " \n",
    "9. error와 복잡도를 고려하는 함수  \n",
    "> argmin { a * Ê(h) + λ * R(h)}  \n",
    "> 'error + 복잡도' 최소화  \n",
    "> 모델 선택 = 함수 선택 = λ 선택 = hyper parameter 튜닝  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. sparcity가 있는 데이터  불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>10</li>\n",
       "\t<li>2</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 10\n",
       "\\item 2\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 10\n",
       "2. 2\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 10  2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t10 obs. of  2 variables:\n",
      " $ input : num  1.236 1.321 1.681 0.201 -1.328 ...\n",
      " $ output: num  1.019 0.88 0.924 0.192 -1.071 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     input              output         \n",
       " Min.   :-1.32752   Min.   :-1.071428  \n",
       " 1st Qu.: 0.07292   1st Qu.:-0.003459  \n",
       " Median : 1.13277   Median : 0.828508  \n",
       " Mean   : 0.67780   Mean   : 0.367047  \n",
       " 3rd Qu.: 1.35469   3rd Qu.: 0.898154  \n",
       " Max.   : 2.12212   Max.   : 1.018728  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>input</th><th scope=col>output</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1.23614288</td><td> 1.01872766</td></tr>\n",
       "\t<tr><td> 1.32125747</td><td> 0.87973679</td></tr>\n",
       "\t<tr><td> 1.68123559</td><td> 0.92391037</td></tr>\n",
       "\t<tr><td> 0.20090028</td><td> 0.19218711</td></tr>\n",
       "\t<tr><td>-1.32752445</td><td>-1.07142803</td></tr>\n",
       "\t<tr><td> 2.12212153</td><td> 0.81891040</td></tr>\n",
       "\t<tr><td> 0.03025799</td><td>-0.06867429</td></tr>\n",
       "\t<tr><td> 1.36583766</td><td> 0.90429301</td></tr>\n",
       "\t<tr><td>-0.88166006</td><td>-0.76530006</td></tr>\n",
       "\t<tr><td> 1.02938745</td><td> 0.83810628</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " input & output\\\\\n",
       "\\hline\n",
       "\t  1.23614288 &  1.01872766\\\\\n",
       "\t  1.32125747 &  0.87973679\\\\\n",
       "\t  1.68123559 &  0.92391037\\\\\n",
       "\t  0.20090028 &  0.19218711\\\\\n",
       "\t -1.32752445 & -1.07142803\\\\\n",
       "\t  2.12212153 &  0.81891040\\\\\n",
       "\t  0.03025799 & -0.06867429\\\\\n",
       "\t  1.36583766 &  0.90429301\\\\\n",
       "\t -0.88166006 & -0.76530006\\\\\n",
       "\t  1.02938745 &  0.83810628\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "input | output | \n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "|  1.23614288 |  1.01872766 | \n",
       "|  1.32125747 |  0.87973679 | \n",
       "|  1.68123559 |  0.92391037 | \n",
       "|  0.20090028 |  0.19218711 | \n",
       "| -1.32752445 | -1.07142803 | \n",
       "|  2.12212153 |  0.81891040 | \n",
       "|  0.03025799 | -0.06867429 | \n",
       "|  1.36583766 |  0.90429301 | \n",
       "| -0.88166006 | -0.76530006 | \n",
       "|  1.02938745 |  0.83810628 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   input       output     \n",
       "1   1.23614288  1.01872766\n",
       "2   1.32125747  0.87973679\n",
       "3   1.68123559  0.92391037\n",
       "4   0.20090028  0.19218711\n",
       "5  -1.32752445 -1.07142803\n",
       "6   2.12212153  0.81891040\n",
       "7   0.03025799 -0.06867429\n",
       "8   1.36583766  0.90429301\n",
       "9  -0.88166006 -0.76530006\n",
       "10  1.02938745  0.83810628"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "# sparcity가 있도록 만든 데이터임!\n",
    "data4_2 <- read.csv(\"data4_2.csv\", header = TRUE) #한글 깨지지 않으려면 encoding=\"utf-8\" 하면됨\n",
    "\n",
    "dim(data4_2)\n",
    "str(data4_2)\n",
    "summary(data4_2)\n",
    "\n",
    "data4_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Linear model 함수 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = output ~ input, data = test_df)\n",
       "\n",
       "Residuals:\n",
       "     Min       1Q   Median       3Q      Max \n",
       "-0.48334 -0.11517  0.03765  0.12446  0.29015 \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value  Pr(>|t|)    \n",
       "(Intercept) -0.07183    0.08931  -0.804     0.445    \n",
       "input        0.64750    0.07037   9.202 0.0000157 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 0.2388 on 8 degrees of freedom\n",
       "Multiple R-squared:  0.9137,\tAdjusted R-squared:  0.9029 \n",
       "F-statistic: 84.67 on 1 and 8 DF,  p-value: 0.00001574\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAFoCAIAAAAAVb93AAAABmJLR0QA/wD/AP+gvaeTAAAg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\nAABOIaABADj1/2DfDb4WGgkzAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Linear model 함수 적용\n",
    "test_df <- data4_2\n",
    "\n",
    "model <- lm(formula=output ~ input, data=test_df)\n",
    "summary(model)\n",
    "\n",
    "plot(test_df$input, test_df$output, pch=19, cex=1)\n",
    "abline(model, lwd = 0.5, col=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. k-fold (k등분)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측:  0.6614561 -0.8129404 0.7360451 \n",
      "실제:  1.018728 -1.071428 0.904293 \n",
      "<오류>:  0.07425539 \n"
     ]
    }
   ],
   "source": [
    "# k 등분해서 진행하기  \n",
    "test_df <- data4_2\n",
    "\n",
    "model <- lm(formula=output ~ input, data=test_df[-c(1,5,8),])\n",
    "\n",
    "#10 개 중 3개 추출\n",
    "pred <- predict(model, test_df[c(1,5,8), ])\n",
    "real <- test_df$output[c(1,5,8)]\n",
    "validation_error <- mean( (real-pred)^2 )\n",
    "\n",
    "cat(\"예측: \" , pred, \"\\n\")\n",
    "cat(\"실제: \" , real, \"\\n\")\n",
    "cat(\"<오류>: \" , validation_error, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. LOO Cross Valiation (leave one out cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "< 1 >차 함수 시작합니다.\n",
      "< 2 >차 함수 시작합니다.\n",
      "< 3 >차 함수 시작합니다.\n",
      "< 4 >차 함수 시작합니다.\n",
      "< 5 >차 함수 시작합니다.\n",
      "< 6 >차 함수 시작합니다.\n",
      "< 7 >차 함수 시작합니다."
     ]
    }
   ],
   "source": [
    "test_df <- data4_2\n",
    "total_basket <- data.frame(matrix(ncol = 4, nrow = 0)) # (6*0)표 만들고\n",
    "colnames(total_basket) <- c(\"k차함수\",\"i번째 학습\", \"error\", \"error_ratio\") # header 만들고\n",
    "\n",
    "for (k in 1:7){\n",
    "    cat(\"\\n<\", k, \">차 함수 시작합니다.\")\n",
    "    validation_error <- 0\n",
    "    \n",
    "    for (i in 1:10){\n",
    "        model <- lm(output ~ poly(input, k), data=test_df[-i,])\n",
    "        pred <- predict(model, test_df[i, ])\n",
    "        real <- test_df$output[i]\n",
    "        validation_error <-  + mean( (real-pred)^2 )\n",
    "        validation_error_ratio <- validation_error/10\n",
    "    }\n",
    "    total_basket[nrow(total_basket) + 1,] = list(k, i, validation_error, validation_error_ratio)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>k차함수</th><th scope=col>i번째 학습</th><th scope=col>error</th><th scope=col>error_ratio</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1           </td><td>10          </td><td>0.074918972 </td><td>0.0074918972</td></tr>\n",
       "\t<tr><td>2           </td><td>10          </td><td>0.016616469 </td><td>0.0016616469</td></tr>\n",
       "\t<tr><td>3           </td><td>10          </td><td>0.001370623 </td><td>0.0001370623</td></tr>\n",
       "\t<tr><td>4           </td><td>10          </td><td>0.001478596 </td><td>0.0001478596</td></tr>\n",
       "\t<tr><td>5           </td><td>10          </td><td>0.002006433 </td><td>0.0002006433</td></tr>\n",
       "\t<tr><td>6           </td><td>10          </td><td>0.015196429 </td><td>0.0015196429</td></tr>\n",
       "\t<tr><td>7           </td><td>10          </td><td>0.136079451 </td><td>0.0136079451</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " k차함수 & i번째 학습 & error & error\\_ratio\\\\\n",
       "\\hline\n",
       "\t 1            & 10           & 0.074918972  & 0.0074918972\\\\\n",
       "\t 2            & 10           & 0.016616469  & 0.0016616469\\\\\n",
       "\t 3            & 10           & 0.001370623  & 0.0001370623\\\\\n",
       "\t 4            & 10           & 0.001478596  & 0.0001478596\\\\\n",
       "\t 5            & 10           & 0.002006433  & 0.0002006433\\\\\n",
       "\t 6            & 10           & 0.015196429  & 0.0015196429\\\\\n",
       "\t 7            & 10           & 0.136079451  & 0.0136079451\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "k차함수 | i번째 학습 | error | error_ratio | \n",
       "|---|---|---|---|---|---|---|\n",
       "| 1            | 10           | 0.074918972  | 0.0074918972 | \n",
       "| 2            | 10           | 0.016616469  | 0.0016616469 | \n",
       "| 3            | 10           | 0.001370623  | 0.0001370623 | \n",
       "| 4            | 10           | 0.001478596  | 0.0001478596 | \n",
       "| 5            | 10           | 0.002006433  | 0.0002006433 | \n",
       "| 6            | 10           | 0.015196429  | 0.0015196429 | \n",
       "| 7            | 10           | 0.136079451  | 0.0136079451 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  k차함수 i번째 학습 error       error_ratio \n",
       "1 1       10         0.074918972 0.0074918972\n",
       "2 2       10         0.016616469 0.0016616469\n",
       "3 3       10         0.001370623 0.0001370623\n",
       "4 4       10         0.001478596 0.0001478596\n",
       "5 5       10         0.002006433 0.0002006433\n",
       "6 6       10         0.015196429 0.0015196429\n",
       "7 7       10         0.136079451 0.0136079451"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAFoCAIAAAAAVb93AAAABmJLR0QA/wD/AP+gvaeTAAAg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\nEdAAYCgCGgAMRUADgKH+H9qRzr198Zg+AAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_basket\n",
    "plot(total_basket$k차함수, total_basket$error_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__해석__\n",
    "3차 함수에서 에러_ratio가 가장 낮음  \n",
    "> 5, 6,7차 함수는 overfitting  \n",
    "1,2차 함수는 underfitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 와인 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mode_all> "
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = quality ~ ., data = test_df)\n",
       "\n",
       "Coefficients:\n",
       "         (Intercept)         fixed_acidity      volatile_acidity  \n",
       "          104.751754              0.085066             -1.492406  \n",
       "         citric_acid        residual_sugar             chlorides  \n",
       "           -0.062621              0.062437             -0.757251  \n",
       " free_sulfur_dioxide  total_sulfur_dioxide               density  \n",
       "            0.004937             -0.001403           -103.909624  \n",
       "                  pH             sulphates               alcohol  \n",
       "            0.498756              0.721744              0.222670  \n",
       "                type  \n",
       "           -0.361332  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data4_1 <- read.csv(\"data4_1.csv\", header = TRUE) #한글 깨지지 않으려면 encoding=\"utf-8\" 하면됨\n",
    "\n",
    "# lm  \n",
    "test_df <- data4_1\n",
    "\n",
    "model_all <- lm(quality ~. , data=test_df)\n",
    "model_type <- lm(quality ~ type , data=test_df)\n",
    "model_residual_sugar <- lm(quality ~ residual_sugar , data=test_df)\n",
    "\n",
    "cat(\"<mode_all> \")\n",
    "model_all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<model_type> "
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = quality ~ type, data = test_df)\n",
       "\n",
       "Coefficients:\n",
       "(Intercept)         type  \n",
       "     5.6360       0.2419  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat(\"<model_type> \")\n",
    "model_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<model_residual_sugar>"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = quality ~ residual_sugar, data = test_df)\n",
       "\n",
       "Coefficients:\n",
       "   (Intercept)  residual_sugar  \n",
       "      5.855323       -0.006787  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat(\"<model_residual_sugar>\")\n",
    "model_residual_sugar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__stepwise Regression__  \n",
    "input의 갯수가 늘어나면 고려해야되는 가설공간이 2배 늘어남,   \n",
    "지금은 파라미터가 12개니까 `r 2^12` 개가 나옴 (2^12)     \n",
    "기하급수적으로 늘어나는 것은 컴퓨터 공학에서 풀 수 없다고 봄     \n",
    " \n",
    "  1. 12*11 / 2로 계산할 수 있음. 4097번이 67으로 줄어들기 때문에, 변수 선택에 중요한 영향을 줌  \n",
    "  2. (통계) 중요한 변수만 들어가면 설명이 가능함  \n",
    "  3. (머신러닝) 중요한 변수만 들어가면 노이즈를 줄임(오버피팅 방지, 가설공간 줄임)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'fixed_acidity'</li>\n",
       "\t<li>'volatile_acidity'</li>\n",
       "\t<li>'citric_acid'</li>\n",
       "\t<li>'residual_sugar'</li>\n",
       "\t<li>'chlorides'</li>\n",
       "\t<li>'free_sulfur_dioxide'</li>\n",
       "\t<li>'total_sulfur_dioxide'</li>\n",
       "\t<li>'density'</li>\n",
       "\t<li>'pH'</li>\n",
       "\t<li>'sulphates'</li>\n",
       "\t<li>'alcohol'</li>\n",
       "\t<li>'quality'</li>\n",
       "\t<li>'type'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'fixed\\_acidity'\n",
       "\\item 'volatile\\_acidity'\n",
       "\\item 'citric\\_acid'\n",
       "\\item 'residual\\_sugar'\n",
       "\\item 'chlorides'\n",
       "\\item 'free\\_sulfur\\_dioxide'\n",
       "\\item 'total\\_sulfur\\_dioxide'\n",
       "\\item 'density'\n",
       "\\item 'pH'\n",
       "\\item 'sulphates'\n",
       "\\item 'alcohol'\n",
       "\\item 'quality'\n",
       "\\item 'type'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'fixed_acidity'\n",
       "2. 'volatile_acidity'\n",
       "3. 'citric_acid'\n",
       "4. 'residual_sugar'\n",
       "5. 'chlorides'\n",
       "6. 'free_sulfur_dioxide'\n",
       "7. 'total_sulfur_dioxide'\n",
       "8. 'density'\n",
       "9. 'pH'\n",
       "10. 'sulphates'\n",
       "11. 'alcohol'\n",
       "12. 'quality'\n",
       "13. 'type'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"fixed_acidity\"        \"volatile_acidity\"     \"citric_acid\"         \n",
       " [4] \"residual_sugar\"       \"chlorides\"            \"free_sulfur_dioxide\" \n",
       " [7] \"total_sulfur_dioxide\" \"density\"              \"pH\"                  \n",
       "[10] \"sulphates\"            \"alcohol\"              \"quality\"             \n",
       "[13] \"type\"                "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = quality ~ fixed_acidity + type, data = test_df)\n",
       "\n",
       "Coefficients:\n",
       "  (Intercept)  fixed_acidity           type  \n",
       "      5.77309       -0.01647        0.21775  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### model_acid_type 결과 보기  \n",
    "\n",
    "test_df <- data4_1\n",
    "\n",
    "model_acid_type <- lm(quality ~ fixed_acidity + type, data=test_df)\n",
    "colnames(test_df)\n",
    "\n",
    "model_acid_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lm 에 type 추가  \n",
    "여기서 +는 수치를 더하는것이 아니라 파라미터 하나 더 추라하는 것  \n",
    "  \n",
    "red가 1, white가 0이니까 red wine가 0.21775의 가중치를 가짐, 1.21775가 더 크다고 볼 수 있다.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 함수의 복잡도 설명 (glmnetUtils)\n",
    "\n",
    "The glmnetUtils package provides a collection of tools to streamline the process of fitting elastic net models with glmnet. \n",
    "\n",
    "elastic net models: Elastic Net 회귀 모형은 가중치의 절대값의 합과 제곱합을 동시에 제약 조건으로 가지는 모형이다.\n",
    "    L1 + L2도 하자.\n",
    "    튜닝파라미터\n",
    "    람다 : 정규화를 얼마나 강하게 할 것이냐? 높으면 정규화가 높다. (모델이 단순하게) 적게 하면 예측률이 높아질듯.\n",
    "    알파 : L1,L2를 몇대 몇으로 할것이냐. 0~1, 알파 : 0 릿지만, 알파 : 1 라쏘만.\n",
    "    \n",
    "    -> 알파와 라쏘를 섞어서 일정 비율로 섞는 하이퍼 파라미터를 사용 \n",
    "https://byungjun0689.github.io/R_for_Data_Science(Machine_Learning_with_R)/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'Y'</li>\n",
       "\t<li>'X1'</li>\n",
       "\t<li>'X2'</li>\n",
       "\t<li>'X3'</li>\n",
       "\t<li>'X4'</li>\n",
       "\t<li>'X5'</li>\n",
       "\t<li>'X6'</li>\n",
       "\t<li>'X7'</li>\n",
       "\t<li>'X8'</li>\n",
       "\t<li>'X9'</li>\n",
       "\t<li>'X10'</li>\n",
       "\t<li>'X11'</li>\n",
       "\t<li>'X12'</li>\n",
       "\t<li>'X13'</li>\n",
       "\t<li>'X14'</li>\n",
       "\t<li>'X15'</li>\n",
       "\t<li>'X16'</li>\n",
       "\t<li>'X17'</li>\n",
       "\t<li>'X18'</li>\n",
       "\t<li>'X19'</li>\n",
       "\t<li>'X20'</li>\n",
       "\t<li>'X21'</li>\n",
       "\t<li>'X22'</li>\n",
       "\t<li>'X23'</li>\n",
       "\t<li>'X24'</li>\n",
       "\t<li>'X25'</li>\n",
       "\t<li>'X26'</li>\n",
       "\t<li>'X27'</li>\n",
       "\t<li>'X28'</li>\n",
       "\t<li>'X29'</li>\n",
       "\t<li>'X30'</li>\n",
       "\t<li>'X31'</li>\n",
       "\t<li>'X32'</li>\n",
       "\t<li>'X33'</li>\n",
       "\t<li>'X34'</li>\n",
       "\t<li>'X35'</li>\n",
       "\t<li>'X36'</li>\n",
       "\t<li>'X37'</li>\n",
       "\t<li>'X38'</li>\n",
       "\t<li>'X39'</li>\n",
       "\t<li>'X40'</li>\n",
       "\t<li>'X41'</li>\n",
       "\t<li>'X42'</li>\n",
       "\t<li>'X43'</li>\n",
       "\t<li>'X44'</li>\n",
       "\t<li>'X45'</li>\n",
       "\t<li>'X46'</li>\n",
       "\t<li>'X47'</li>\n",
       "\t<li>'X48'</li>\n",
       "\t<li>'X49'</li>\n",
       "\t<li>'X50'</li>\n",
       "\t<li>'X51'</li>\n",
       "\t<li>'X52'</li>\n",
       "\t<li>'X53'</li>\n",
       "\t<li>'X54'</li>\n",
       "\t<li>'X55'</li>\n",
       "\t<li>'X56'</li>\n",
       "\t<li>'X57'</li>\n",
       "\t<li>'X58'</li>\n",
       "\t<li>'X59'</li>\n",
       "\t<li>'X60'</li>\n",
       "\t<li>'X61'</li>\n",
       "\t<li>'X62'</li>\n",
       "\t<li>'X63'</li>\n",
       "\t<li>'X64'</li>\n",
       "\t<li>'X65'</li>\n",
       "\t<li>'X66'</li>\n",
       "\t<li>'X67'</li>\n",
       "\t<li>'X68'</li>\n",
       "\t<li>'X69'</li>\n",
       "\t<li>'X70'</li>\n",
       "\t<li>'X71'</li>\n",
       "\t<li>'X72'</li>\n",
       "\t<li>'X73'</li>\n",
       "\t<li>'X74'</li>\n",
       "\t<li>'X75'</li>\n",
       "\t<li>'X76'</li>\n",
       "\t<li>'X77'</li>\n",
       "\t<li>'X78'</li>\n",
       "\t<li>'X79'</li>\n",
       "\t<li>'X80'</li>\n",
       "\t<li>'X81'</li>\n",
       "\t<li>'X82'</li>\n",
       "\t<li>'X83'</li>\n",
       "\t<li>'X84'</li>\n",
       "\t<li>'X85'</li>\n",
       "\t<li>'X86'</li>\n",
       "\t<li>'X87'</li>\n",
       "\t<li>'X88'</li>\n",
       "\t<li>'X89'</li>\n",
       "\t<li>'X90'</li>\n",
       "\t<li>'X91'</li>\n",
       "\t<li>'X92'</li>\n",
       "\t<li>'X93'</li>\n",
       "\t<li>'X94'</li>\n",
       "\t<li>'X95'</li>\n",
       "\t<li>'X96'</li>\n",
       "\t<li>'X97'</li>\n",
       "\t<li>'X98'</li>\n",
       "\t<li>'X99'</li>\n",
       "\t<li>'X100'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'Y'\n",
       "\\item 'X1'\n",
       "\\item 'X2'\n",
       "\\item 'X3'\n",
       "\\item 'X4'\n",
       "\\item 'X5'\n",
       "\\item 'X6'\n",
       "\\item 'X7'\n",
       "\\item 'X8'\n",
       "\\item 'X9'\n",
       "\\item 'X10'\n",
       "\\item 'X11'\n",
       "\\item 'X12'\n",
       "\\item 'X13'\n",
       "\\item 'X14'\n",
       "\\item 'X15'\n",
       "\\item 'X16'\n",
       "\\item 'X17'\n",
       "\\item 'X18'\n",
       "\\item 'X19'\n",
       "\\item 'X20'\n",
       "\\item 'X21'\n",
       "\\item 'X22'\n",
       "\\item 'X23'\n",
       "\\item 'X24'\n",
       "\\item 'X25'\n",
       "\\item 'X26'\n",
       "\\item 'X27'\n",
       "\\item 'X28'\n",
       "\\item 'X29'\n",
       "\\item 'X30'\n",
       "\\item 'X31'\n",
       "\\item 'X32'\n",
       "\\item 'X33'\n",
       "\\item 'X34'\n",
       "\\item 'X35'\n",
       "\\item 'X36'\n",
       "\\item 'X37'\n",
       "\\item 'X38'\n",
       "\\item 'X39'\n",
       "\\item 'X40'\n",
       "\\item 'X41'\n",
       "\\item 'X42'\n",
       "\\item 'X43'\n",
       "\\item 'X44'\n",
       "\\item 'X45'\n",
       "\\item 'X46'\n",
       "\\item 'X47'\n",
       "\\item 'X48'\n",
       "\\item 'X49'\n",
       "\\item 'X50'\n",
       "\\item 'X51'\n",
       "\\item 'X52'\n",
       "\\item 'X53'\n",
       "\\item 'X54'\n",
       "\\item 'X55'\n",
       "\\item 'X56'\n",
       "\\item 'X57'\n",
       "\\item 'X58'\n",
       "\\item 'X59'\n",
       "\\item 'X60'\n",
       "\\item 'X61'\n",
       "\\item 'X62'\n",
       "\\item 'X63'\n",
       "\\item 'X64'\n",
       "\\item 'X65'\n",
       "\\item 'X66'\n",
       "\\item 'X67'\n",
       "\\item 'X68'\n",
       "\\item 'X69'\n",
       "\\item 'X70'\n",
       "\\item 'X71'\n",
       "\\item 'X72'\n",
       "\\item 'X73'\n",
       "\\item 'X74'\n",
       "\\item 'X75'\n",
       "\\item 'X76'\n",
       "\\item 'X77'\n",
       "\\item 'X78'\n",
       "\\item 'X79'\n",
       "\\item 'X80'\n",
       "\\item 'X81'\n",
       "\\item 'X82'\n",
       "\\item 'X83'\n",
       "\\item 'X84'\n",
       "\\item 'X85'\n",
       "\\item 'X86'\n",
       "\\item 'X87'\n",
       "\\item 'X88'\n",
       "\\item 'X89'\n",
       "\\item 'X90'\n",
       "\\item 'X91'\n",
       "\\item 'X92'\n",
       "\\item 'X93'\n",
       "\\item 'X94'\n",
       "\\item 'X95'\n",
       "\\item 'X96'\n",
       "\\item 'X97'\n",
       "\\item 'X98'\n",
       "\\item 'X99'\n",
       "\\item 'X100'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'Y'\n",
       "2. 'X1'\n",
       "3. 'X2'\n",
       "4. 'X3'\n",
       "5. 'X4'\n",
       "6. 'X5'\n",
       "7. 'X6'\n",
       "8. 'X7'\n",
       "9. 'X8'\n",
       "10. 'X9'\n",
       "11. 'X10'\n",
       "12. 'X11'\n",
       "13. 'X12'\n",
       "14. 'X13'\n",
       "15. 'X14'\n",
       "16. 'X15'\n",
       "17. 'X16'\n",
       "18. 'X17'\n",
       "19. 'X18'\n",
       "20. 'X19'\n",
       "21. 'X20'\n",
       "22. 'X21'\n",
       "23. 'X22'\n",
       "24. 'X23'\n",
       "25. 'X24'\n",
       "26. 'X25'\n",
       "27. 'X26'\n",
       "28. 'X27'\n",
       "29. 'X28'\n",
       "30. 'X29'\n",
       "31. 'X30'\n",
       "32. 'X31'\n",
       "33. 'X32'\n",
       "34. 'X33'\n",
       "35. 'X34'\n",
       "36. 'X35'\n",
       "37. 'X36'\n",
       "38. 'X37'\n",
       "39. 'X38'\n",
       "40. 'X39'\n",
       "41. 'X40'\n",
       "42. 'X41'\n",
       "43. 'X42'\n",
       "44. 'X43'\n",
       "45. 'X44'\n",
       "46. 'X45'\n",
       "47. 'X46'\n",
       "48. 'X47'\n",
       "49. 'X48'\n",
       "50. 'X49'\n",
       "51. 'X50'\n",
       "52. 'X51'\n",
       "53. 'X52'\n",
       "54. 'X53'\n",
       "55. 'X54'\n",
       "56. 'X55'\n",
       "57. 'X56'\n",
       "58. 'X57'\n",
       "59. 'X58'\n",
       "60. 'X59'\n",
       "61. 'X60'\n",
       "62. 'X61'\n",
       "63. 'X62'\n",
       "64. 'X63'\n",
       "65. 'X64'\n",
       "66. 'X65'\n",
       "67. 'X66'\n",
       "68. 'X67'\n",
       "69. 'X68'\n",
       "70. 'X69'\n",
       "71. 'X70'\n",
       "72. 'X71'\n",
       "73. 'X72'\n",
       "74. 'X73'\n",
       "75. 'X74'\n",
       "76. 'X75'\n",
       "77. 'X76'\n",
       "78. 'X77'\n",
       "79. 'X78'\n",
       "80. 'X79'\n",
       "81. 'X80'\n",
       "82. 'X81'\n",
       "83. 'X82'\n",
       "84. 'X83'\n",
       "85. 'X84'\n",
       "86. 'X85'\n",
       "87. 'X86'\n",
       "88. 'X87'\n",
       "89. 'X88'\n",
       "90. 'X89'\n",
       "91. 'X90'\n",
       "92. 'X91'\n",
       "93. 'X92'\n",
       "94. 'X93'\n",
       "95. 'X94'\n",
       "96. 'X95'\n",
       "97. 'X96'\n",
       "98. 'X97'\n",
       "99. 'X98'\n",
       "100. 'X99'\n",
       "101. 'X100'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  [1] \"Y\"    \"X1\"   \"X2\"   \"X3\"   \"X4\"   \"X5\"   \"X6\"   \"X7\"   \"X8\"   \"X9\"  \n",
       " [11] \"X10\"  \"X11\"  \"X12\"  \"X13\"  \"X14\"  \"X15\"  \"X16\"  \"X17\"  \"X18\"  \"X19\" \n",
       " [21] \"X20\"  \"X21\"  \"X22\"  \"X23\"  \"X24\"  \"X25\"  \"X26\"  \"X27\"  \"X28\"  \"X29\" \n",
       " [31] \"X30\"  \"X31\"  \"X32\"  \"X33\"  \"X34\"  \"X35\"  \"X36\"  \"X37\"  \"X38\"  \"X39\" \n",
       " [41] \"X40\"  \"X41\"  \"X42\"  \"X43\"  \"X44\"  \"X45\"  \"X46\"  \"X47\"  \"X48\"  \"X49\" \n",
       " [51] \"X50\"  \"X51\"  \"X52\"  \"X53\"  \"X54\"  \"X55\"  \"X56\"  \"X57\"  \"X58\"  \"X59\" \n",
       " [61] \"X60\"  \"X61\"  \"X62\"  \"X63\"  \"X64\"  \"X65\"  \"X66\"  \"X67\"  \"X68\"  \"X69\" \n",
       " [71] \"X70\"  \"X71\"  \"X72\"  \"X73\"  \"X74\"  \"X75\"  \"X76\"  \"X77\"  \"X78\"  \"X79\" \n",
       " [81] \"X80\"  \"X81\"  \"X82\"  \"X83\"  \"X84\"  \"X85\"  \"X86\"  \"X87\"  \"X88\"  \"X89\" \n",
       " [91] \"X90\"  \"X91\"  \"X92\"  \"X93\"  \"X94\"  \"X95\"  \"X96\"  \"X97\"  \"X98\"  \"X99\" \n",
       "[101] \"X100\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(\"glmnetUtils\")\n",
    "data4_3 <- read.csv(\"data4_3.csv\", header = TRUE) #한글 깨지지 않으려면 encoding=\"utf-8\" 하면됨\n",
    "\n",
    "test_df <- data4_3\n",
    "colnames(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = Y ~ ., data = test_df)\n",
       "\n",
       "Coefficients:\n",
       "(Intercept)           X1           X2           X3           X4           X5  \n",
       "   1.257008     1.065963     0.023143     0.023425    -0.069477    -0.080231  \n",
       "         X6           X7           X8           X9          X10          X11  \n",
       "   0.056536    -0.035723    -0.031815     0.152955    -0.012982    -0.064110  \n",
       "        X12          X13          X14          X15          X16          X17  \n",
       "   0.017474     0.117016    -0.032945     0.015036    -0.246596    -0.108870  \n",
       "        X18          X19          X20          X21          X22          X23  \n",
       "  -0.131736     0.181305    -0.006779     0.112091     0.095405     0.063288  \n",
       "        X24          X25          X26          X27          X28          X29  \n",
       "  -0.052944    -0.003376    -0.026710     0.247813    -0.009410    -0.048134  \n",
       "        X30          X31          X32          X33          X34          X35  \n",
       "  -0.044487    -0.095561    -0.156647    -0.042266     0.112269     0.193337  \n",
       "        X36          X37          X38          X39          X40          X41  \n",
       "  -0.009977    -0.007624     0.138271    -0.022279    -0.053125     0.076579  \n",
       "        X42          X43          X44          X45          X46          X47  \n",
       "  -0.020526     0.061609     0.138769    -0.129197    -0.051660     0.055959  \n",
       "        X48          X49          X50          X51          X52          X53  \n",
       "  -0.015451     0.050696     1.844057     0.043100     0.019202     0.074139  \n",
       "        X54          X55          X56          X57          X58          X59  \n",
       "   0.045271     0.035127    -0.008514    -0.005816    -0.056528    -0.046850  \n",
       "        X60          X61          X62          X63          X64          X65  \n",
       "   0.046566     0.062639    -0.106560     0.017154    -0.099002     0.067973  \n",
       "        X66          X67          X68          X69          X70          X71  \n",
       "  -0.080119     0.051963     0.163752    -0.039898     2.993952     0.012700  \n",
       "        X72          X73          X74          X75          X76          X77  \n",
       "   0.092739     0.067774    -0.071860    -0.002685     0.033593    -0.010826  \n",
       "        X78          X79          X80          X81          X82          X83  \n",
       "  -0.115510     0.070332    -1.023690     0.159778    -0.042075     0.027155  \n",
       "        X84          X85          X86          X87          X88          X89  \n",
       "   0.221621    -0.003188     0.083880     0.004072    -0.017214    -0.068442  \n",
       "        X90          X91          X92          X93          X94          X95  \n",
       "  -0.138030     0.035861    -0.077178     0.110371     0.048320     0.010864  \n",
       "        X96          X97          X98          X99         X100  \n",
       "   0.041291    -0.081461    -0.049578     0.066385    -0.023610  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df <- data4_3\n",
    "\n",
    "model <- lm(Y ~., test_df)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "4.67178508485376"
      ],
      "text/latex": [
       "4.67178508485376"
      ],
      "text/markdown": [
       "4.67178508485376"
      ],
      "text/plain": [
       "[1] 4.671785"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lambda는 1일 때\n",
    "test_df <- data4_3\n",
    "set.seed(123)\n",
    "\n",
    "train <- sample(1:nrow(test_df), 0.7 * nrow(test_df))\n",
    "\n",
    "model <- glmnet(Y ~., \n",
    "                    data = test_df[train, ],\n",
    "                    lambda = 1 ) # 70% 선택했으니 train set\n",
    "\n",
    "pred <- predict(model, test_df[-train, ])\n",
    "real <- test_df$Y[-train]\n",
    "validation_Error <- mean((real - pred) ^ 2)\n",
    "\n",
    "validation_Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lambda  0 의 validation_error는  2.816874 입니다.\n",
      "lambda  0.1 의 validation_error는  1.041327 입니다.\n",
      "lambda  0.5 의 validation_error는  1.723713 입니다.\n",
      "lambda  1 의 validation_error는  4.671785 입니다."
     ]
    }
   ],
   "source": [
    "# lambda는 가 list일때 \n",
    "total_basket2 <- data.frame(matrix(ncol = 2, nrow = 0)) # (6*0)표 만들고\n",
    "colnames(total_basket2) <- c(\"lambda\", \"error\") # header 만들고\n",
    "\n",
    "lambda_example = list(0, 0.1, 0.5, 1)\n",
    "\n",
    "for (lambda in lambda_example){\n",
    "    test_df <- data4_3\n",
    "    set.seed(123)\n",
    "    \n",
    "    train <- sample(1:nrow(test_df), 0.7 * nrow(test_df))\n",
    "    model <- glmnet(Y ~., \n",
    "                        data = test_df[train, ],\n",
    "                        lambda = lambda ) # 70% 선택했으니 train set\n",
    "\n",
    "    pred <- predict(model, test_df[-train, ])\n",
    "    real <- test_df$Y[-train]\n",
    "    validation_Error <- mean((real - pred) ^ 2)\n",
    "\n",
    "    cat('\\nlambda ', lambda, '의 validation_error는 ' , validation_Error , '입니다.')\n",
    "    total_basket2[nrow(total_basket2) + 1,] = list(lambda, validation_Error)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAFoCAIAAAAAVb93AAAABmJLR0QA/wD/AP+gvaeTAAAg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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plot(total_basket2$lambda, total_basket2$error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>2</li>\n",
       "\t<li>4</li>\n",
       "\t<li>1</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 2\n",
       "\\item 4\n",
       "\\item 1\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 2\n",
       "2. 4\n",
       "3. 1\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 2 4 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1</li>\n",
       "\t<li>3</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1\n",
       "\\item 3\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1\n",
       "2. 3\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1</li>\n",
       "\t<li>4</li>\n",
       "\t<li>3</li>\n",
       "\t<li>2</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1\n",
       "\\item 4\n",
       "\\item 3\n",
       "\\item 2\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1\n",
       "2. 4\n",
       "3. 3\n",
       "4. 2\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1 4 3 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sample() 함수  \n",
    "#  무작위로 특정 행까지 뽑는 함수, 반복해서 실행하면 다르게 나옴\n",
    "sample(c(1,2,3,4), 3)\n",
    "sample(c(1,2,3,4), 2)\n",
    "sample(c(1,2,3,4), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>1</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 1\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 2\n",
       "2. 3\n",
       "3. 1\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 2 3 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>4</li>\n",
       "\t<li>3</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 4\n",
       "\\item 3\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 4\n",
       "2. 3\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 4 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1</li>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>4</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 4\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1\n",
       "2. 2\n",
       "3. 3\n",
       "4. 4\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1 2 3 4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sample() 함수  \n",
    "set.seed(123)\n",
    "# set.seed 해주면 변하지 않음\n",
    "sample(c(1,2,3,4), 3)\n",
    "sample(c(1,2,3,4), 2)\n",
    "sample(c(1,2,3,4), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__6강에서 배울 내용__  \n",
    "\n",
    ">kaggle 데이터 실습  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
